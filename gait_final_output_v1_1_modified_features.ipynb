{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5480bcf3-0e3d-47c8-966f-75acdcf20c47",
   "metadata": {},
   "source": [
    "Gait Analysis (baseline approach (as in gait_final_output_v1_1.ipynb) with R1, R2, R3 transfomed into mean, mediam and std)\n",
    "\n",
    "Aim: \n",
    "- Multi-class classification (16 subjects) using train/test split with SMOTE-based oversampling in pipeline - the first attempt/baseline approach.\n",
    "\n",
    "Data Source/Credit: \n",
    "- https://archive.ics.uci.edu/dataset/604/gait+classification\n",
    "\n",
    "Dataset\n",
    "- Size:         48 samples (16 subjects * 3 trials)\n",
    "- Features:     Transformed features into mean, median and mode for R1, R2 and R3 to derive new 321 features and use those for classification.\n",
    "- Target:       Subject identification (16 classes)\n",
    "- Missing data: 1 NA value in CycleTime_R2 (imputed with median)\n",
    "- Split:        67% train / 33% test -> ~2 training samples/class + 1 test sample/class\n",
    "\n",
    "Conclusion from this analysis: \n",
    "- Reduced performance compared to gait_final_output_v1_1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2e62606-7b54-4233-bb84-9090b1662aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5dcf0aa1-78d5-4eb5-b62b-bf2945b67692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import LeaveOneOut, LeaveOneGroupOut, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# these clean up the noisy data\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# these do not clean up the noisy data\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN, SMOTE\n",
    "\n",
    "# avoid as it only duplicates data\n",
    "# from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fa664d4-5a6e-41dc-a9b9-5e27dc9ddd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new.shape: (48, 321)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed_R1</th>\n",
       "      <th>Variability_R1</th>\n",
       "      <th>Symmetry_R1</th>\n",
       "      <th>HeelPressTime_R1</th>\n",
       "      <th>CycleTime_R1</th>\n",
       "      <th>Cadence_R1</th>\n",
       "      <th>Posture_R1</th>\n",
       "      <th>Oscillation_R1</th>\n",
       "      <th>Loading_R1</th>\n",
       "      <th>FootPress_R1</th>\n",
       "      <th>...</th>\n",
       "      <th>P99_R3</th>\n",
       "      <th>P100_R3</th>\n",
       "      <th>P101_R3</th>\n",
       "      <th>P102_R3</th>\n",
       "      <th>P103_R3</th>\n",
       "      <th>P104_R3</th>\n",
       "      <th>P105_R3</th>\n",
       "      <th>P106_R3</th>\n",
       "      <th>P107_R3</th>\n",
       "      <th>Subject_ID_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.41</td>\n",
       "      <td>5.92</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.073</td>\n",
       "      <td>1.073</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.187</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.27</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.113</td>\n",
       "      <td>1.112</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.115</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.34</td>\n",
       "      <td>4.71</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1.132</td>\n",
       "      <td>1.133</td>\n",
       "      <td>1.135</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.316</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Speed_R1  Variability_R1  Symmetry_R1  HeelPressTime_R1  CycleTime_R1  \\\n",
       "24      1.41            5.92         -4.9             1.069         1.068   \n",
       "20      1.27            4.12          1.8             1.113         1.112   \n",
       "22      1.34            4.71         -0.7             1.132         1.133   \n",
       "\n",
       "    Cadence_R1  Posture_R1  Oscillation_R1  Loading_R1  FootPress_R1  ...  \\\n",
       "24       1.073       1.073           0.046       0.063         0.055  ...   \n",
       "20       1.115       1.115           0.044       0.046         0.040  ...   \n",
       "22       1.135       1.125           0.073       0.053         0.067  ...   \n",
       "\n",
       "    P99_R3  P100_R3  P101_R3  P102_R3  P103_R3  P104_R3  P105_R3  P106_R3  \\\n",
       "24   0.014    0.027    0.019    0.061    0.121    0.201    0.187    1.010   \n",
       "20   0.020    0.026    0.027    0.130    0.128    0.216    0.216    1.010   \n",
       "22   0.024    0.045    0.018    0.057   -0.033    0.208    0.125    1.316   \n",
       "\n",
       "    P107_R3  Subject_ID_Y  \n",
       "24     0.99             8  \n",
       "20     0.99             6  \n",
       "22     0.76             7  \n",
       "\n",
       "[3 rows x 322 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('gait_final_output_updated.csv')\n",
    "print(f'df_new.shape: {df_new.shape}')\n",
    "print(\"---\")\n",
    "df.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51ea8ff8-0c0f-4681-8663-9cefc44dc58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Classes are balanced. Max-to-min count ratio is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "\n",
    "print( df['Subject_ID_Y'].value_counts().to_list() )\n",
    "\n",
    "min_y_count = df['Subject_ID_Y'].value_counts().min()\n",
    "max_y_count = df['Subject_ID_Y'].value_counts().max()\n",
    "\n",
    "if min_y_count/max_y_count > 5: \n",
    "    print(f\"Classes are imbalanced. Max-to-min count ratio is: {min_y_count/max_y_count}\")\n",
    "else:\n",
    "    print(f\"Classes are balanced. Max-to-min count ratio is: {min_y_count/max_y_count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee93b600-fcef-4a89-8d41-0e81cae01d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new.shape (48, 321)\n"
     ]
    }
   ],
   "source": [
    "# Form a new df, with mean, meadian and mode using df_new\n",
    "\n",
    "cols_to_aggregate, prefixes = [], []\n",
    "\n",
    "# identify columns to aggregate (excluding target)\n",
    "cols_to_aggregate = [col for col in df.columns if col!='Subject_ID_Y']\n",
    "# print( \"cols_to_aggregate:\",cols_to_affregate )\n",
    "\n",
    "# extract unique prefix before the underscore\n",
    "prefixes =  [col.split('_') for col in cols_to_aggregate] \n",
    "# print(\"prefixes:\", prefixes ) # list of lists\n",
    "\n",
    "# create a new dictionary\n",
    "new_columns = {}\n",
    "\n",
    "for prefix in prefixes:\n",
    "    # print(f\"prefix:{prefix} | first_val:{prefix[0]}\")\n",
    "    # find all columns with prefix prefix[0]\n",
    "    # print(\"prefix[0]:\", prefix[0])\n",
    "    matching_cols = [ col for col in cols_to_aggregate if col.startswith( prefix[0] ) ]\n",
    "    # print( \"matching_cols\", matching_cols )    \n",
    "    \n",
    "    if len(matching_cols) <3 :\n",
    "        print(f\"Either the matching_cols list is empty or has less than 3 columns\")    \n",
    "        \n",
    "    elif len(matching_cols) == 3: # we know it has 3 columns, R1, R2, R3\n",
    "        # calculate mean, median and mode\n",
    "        new_columns[f'{prefix[0]}_mean']   = df[matching_cols].mean(axis=1)\n",
    "        new_columns[f'{prefix[0]}_median'] = df[matching_cols].median(axis=1)\n",
    "        new_columns[f'{prefix[0]}_std']    = df[matching_cols].std(axis=1)\n",
    "        \n",
    "# create a dataframe from this dictionary \n",
    "df_new = pd.DataFrame(new_columns)\n",
    "print( \"df_new.shape\", df_new.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8ef2ca3-9c2e-4880-966e-f89c937a68df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speed_mean            float64\n",
       "Speed_median          float64\n",
       "Speed_std             float64\n",
       "Variability_mean      float64\n",
       "Variability_median    float64\n",
       "                       ...   \n",
       "P106_median           float64\n",
       "P106_std              float64\n",
       "P107_mean             float64\n",
       "P107_median           float64\n",
       "P107_std              float64\n",
       "Length: 321, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "df_new.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eae384e3-013d-49c1-83cb-7e41a820a3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speed_mean            0\n",
       "Speed_median          0\n",
       "Speed_std             0\n",
       "Variability_mean      0\n",
       "Variability_median    0\n",
       "                     ..\n",
       "P106_median           0\n",
       "P106_std              0\n",
       "P107_mean             0\n",
       "P107_median           0\n",
       "P107_std              0\n",
       "Length: 321, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check empty values\n",
    "df_new.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c8688c6-9e33-4387-b2a4-bf00c200d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 48\n",
      "Total features: 321\n",
      "Number of classes: 16\n",
      "Class distribution in full dataset:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# STEP 0: Split X and y\n",
    "\n",
    "y =  df['Subject_ID_Y']\n",
    "X =  df_new\n",
    "\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"Number of classes: {len(y.unique())}\")\n",
    "print(f\"Class distribution in full dataset:\")\n",
    "print(y.value_counts().sort_index().to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef03859e-9489-44b9-9a01-33575f764646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== smoteenn ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smoteenn\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       0.50      1.00      0.67         1\n",
      "           6       0.50      1.00      0.67         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       0.33      1.00      0.50         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.27      0.44      0.32        16\n",
      "weighted avg       0.27      0.44      0.32        16\n",
      "\n",
      "\n",
      "=== smotetomek ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smotetomek\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       0.50      1.00      0.67         1\n",
      "           6       0.50      1.00      0.67         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       0.33      1.00      0.50         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.27      0.44      0.32        16\n",
      "weighted avg       0.27      0.44      0.32        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define oversampler TYPES\n",
    "oversampler_types = ['smoteenn', 'smotetomek']\n",
    "oversampler_count = len(oversampler_types)\n",
    "\n",
    "for key in oversampler_types:\n",
    "    print(f'\\n=== {key} ===')\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42 )\n",
    "    print(\"y_train distribution:\", y_train.value_counts().sort_index().to_list())\n",
    "    \n",
    "    # Get sample counts in train data\n",
    "    n_samples = y_train.value_counts().min()\n",
    "    k_neighbors = max(1, min(3, n_samples - 1))\n",
    "    print(\"k_neighbors:\", k_neighbors)\n",
    "    print(\"y_train.value_counts().min():\", n_samples)\n",
    "    \n",
    "    # Choose appropriate oversampler based on sample size\n",
    "    if n_samples < 6:  # Too few samples for SMOTEENN/SMOTETomek\n",
    "        print(f\"Only {n_samples} samples per class - using RandomOverSampler instead of {key}\")\n",
    "        oversampler = RandomOverSampler(random_state=42)\n",
    "    else:\n",
    "        sampling_strategy = {cls: target_samples_per_class for cls in np.unique(y_train)}\n",
    "        \n",
    "        if key == 'smoteenn':\n",
    "            oversampler = SMOTEENN(\n",
    "                smote=SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors=k_neighbors),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "        elif key == 'smotetomek':\n",
    "            oversampler = SMOTETomek(\n",
    "                smote=SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors=k_neighbors),\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "    print(\"oversampler used: \", oversampler)    \n",
    "    \n",
    "    # Pipeline with GaussianNB\n",
    "    max_k = min(10, X_train.shape[1], len(X_train) // 10)\n",
    "    pipeline = Pipeline([\n",
    "        ('oversample', oversampler),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('selector', SelectKBest(mutual_info_classif, k=max_k)),\n",
    "        ('model', GaussianNB())\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        # Check if we have enough samples for cross-validation\n",
    "        if n_samples < 3:\n",
    "            print(f\"Skipping cross-validation - only {n_samples} samples per class\")\n",
    "            print(\"Training on training set and evaluating on test set only...\")\n",
    "            \n",
    "            # Just fit on training data and evaluate on test\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred_test = pipeline.predict(X_test)\n",
    "            \n",
    "            print(\"\\nTest Report:\")\n",
    "            print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "        else:\n",
    "            # Cross-validation\n",
    "            n_splits = min(5, n_samples)\n",
    "            cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "            \n",
    "            y_pred_train = cross_val_predict(pipeline, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "            print(\"\\nTraining CV Report:\")\n",
    "            print(classification_report(y_train, y_pred_train, zero_division=0))\n",
    "            \n",
    "            # Final evaluation\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred_test = pipeline.predict(X_test)\n",
    "            print(\"\\nTest Report:\")\n",
    "            print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error with {key}: {e}\")\n",
    "        print(\"Debug info:\")\n",
    "        print(f\"  - X_train shape: {X_train.shape}\")\n",
    "        print(f\"  - y_train distribution: {y_train.value_counts().to_dict()}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d5a97-df9b-416a-900f-cf0b3cf70d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57be86fe-7f9e-4bd0-949d-43786d2df9e9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103032aa-61ed-45a1-b029-04f2d69c5df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
