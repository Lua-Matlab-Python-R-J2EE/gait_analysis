{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55315447-33f0-4a80-bae1-03c7c6ee46b1",
   "metadata": {},
   "source": [
    "GAIT ANALYSIS (Leave-One-Out cross-validation (LOOCV) with pre-CV oversampling, without train/test split)\n",
    "\n",
    "Aim: Multi-class classification (16 subjects) with oversampling applied before splitting data into train/test sets.\n",
    "- Can features distinguish between subjects?\n",
    "\n",
    "Data Credits: https://archive.ics.uci.edu/dataset/604/gait+classification\n",
    "\n",
    "Dataset:\n",
    "- Before Oversampling: 48 samples, 16 classes (3/class)\n",
    "- After Oversampling:  480 samples (30/class)\n",
    "- CV:                  480 folds   (1/oversampled sample)\n",
    "  \n",
    "Approach:\n",
    "- 1. Oversampling: Apply SMOTE/RandomOverSampler to balance all classes to 30 samples each. \n",
    "- 2. CV:           Leave-One-Out CV on the already oversampled dataset (train on 479 samples / test on 1 sample)\n",
    "- 3. Pipeline:     StandardScaler -> SelectKBest/k=5 -> SVM/RBF kernel (rather than KNeighbors)\n",
    "\n",
    "Why?\n",
    "- With extramly small data, LOOCV maximizes the use of available data.\n",
    "- Maximizes training data usage (479 out of 480 samples per fold)\n",
    "- LOOCV provides a nearly unbiased estimate of model performance on the available data.\n",
    "- Appropriate for extremely small datasets as each iteration gets maximum training samples\n",
    "\n",
    "Upside:\n",
    "- Near-perfect accuracy (99.4%) demonstrates strong feature discriminability on seen subjects only.\n",
    "- LOOCV maximizes training data usage for each fold.\n",
    "- Almost all classes achieve perfect precision and recall.\n",
    "- Only one or two subjects/classes show minor misclassifications.\n",
    "\n",
    "Downside: data leakage due to pre-CV oversampling:\n",
    "- Oversampling (SMOTE/RandomOverSampler) creates synthetic samples based on existing data\n",
    "- When oversampling before CV, synthetic samples derived from the same original sample can appear in both training and test sets\n",
    "- In each CV fold, the test sample may be nearly identical to synthetic samples in the training set\n",
    "- The model is tested on variations of data it has already seen during training\n",
    "- This leads to the model memorizing patterns (overfitting) from the same original samples, resulting in inflated accuracy\n",
    "- Results are severely over-optimistic and do not reflect true generalization ability\n",
    "- The fundamental assumption of independent test samples is violated\n",
    "\n",
    "Valid Interpretation\n",
    "- Features CAN distinguish between subjects when sufficient samples are available\n",
    "- Proof of concept that the gait measurements contain subject-specific patterns\n",
    "- Feature discriminability is confirmed\n",
    "  \n",
    "Invalid Interpretation\n",
    "- NOT real-world accuracy on unseen subjects\n",
    "- NOT generalizable to new people\n",
    "- NOT deployment-ready performance estimate\n",
    "\n",
    "Summary:\n",
    "- This approach is INVALID for true performance estimation (as explain in the 'Downside' point).\n",
    "- The 99.4% accuracy does not represent real-world performance on unseen subjects.\n",
    "- Correct approach: Oversample within each LOOCV fold (oversample training set only, never the test sample).\n",
    "\n",
    "Conclusion:\n",
    "- While this experiment confirms that the features can distinguish between subjects when given enough synthetic examples, \n",
    "    the methodology fundamentally violates the principle of keeping training and test data independent. \n",
    "        The near-perfect results are an artifact of data leakage, not genuine model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7f181-7b3d-4f8b-8429-902bdc070cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e24ce5-a8ff-475b-bf2d-6ba13b9c7899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LEAVE-ONE-OUT CV ON OVERSAMPLED DATA\n",
      "======================================================================\n",
      "Original: 48 samples, 16 classes\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LEAVE-ONE-OUT CV ON OVERSAMPLED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"gait_final_output_updated.csv\")\n",
    "X = df.drop(\"Subject_ID_Y\", axis=1)\n",
    "y = df[\"Subject_ID_Y\"]\n",
    "\n",
    "print(f\"Original: {len(y)} samples, {len(y.unique())} classes\")\n",
    "\n",
    "# Oversample FIRST\n",
    "target_per_class = 30  # Conservative\n",
    "\n",
    "min_samples = y.value_counts().min()\n",
    "if min_samples >= 3:\n",
    "    oversampler = SMOTE(random_state=42, k_neighbors=2,\n",
    "                       sampling_strategy={cls: target_per_class for cls in np.unique(y)})\n",
    "else:    \n",
    "    oversampler = RandomOverSampler(random_state=42, \n",
    "                                   sampling_strategy={cls: target_per_class for cls in np.unique(y)})\n",
    "\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "print(f\"Oversampled: {len(y_resampled)} samples\")\n",
    "print(f\"Samples per class: {target_per_class}\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler() ),\n",
    "    (\"feature_selector\", SelectKBest(mutual_info_classif, k=5) ),  \n",
    "    (\"clf\", SVC(kernel=\"rbf\", C=1.0, gamma='scale', random_state=42) )\n",
    "])\n",
    "\n",
    "# Leave-One-Out CV\n",
    "loo = LeaveOneOut()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "print(f\"\\nRunning LOO CV on {len(y_resampled)} samples...\")\n",
    "print(\"(This may take a few minutes...)\")\n",
    "\n",
    "# Define a function for a single fold\n",
    "def run_fold(train_idx, test_idx):\n",
    "    X_train_fold = X_resampled.iloc[train_idx]\n",
    "    X_test_fold = X_resampled.iloc[test_idx]\n",
    "    y_train_fold = y_resampled.iloc[train_idx]\n",
    "    y_test_fold = y_resampled.iloc[test_idx]\n",
    "    \n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "    y_pred = pipeline.predict(X_test_fold)\n",
    "    # returns an array with one element (e.g., [label]), since only one sample is tested each fold.\n",
    "    return y_pred[0], y_test_fold.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2761ccb-624a-463b-a1fe-ffe79a4a33e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 33.6min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 57.2min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 63.0min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 69.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 74.4min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 78.7min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 80.0min finished\n"
     ]
    }
   ],
   "source": [
    "# This line runs all LOOCV folds in parallel, each calling run_fold() \n",
    "# with the respective train/test indices, and collects their outputs.\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=10)( delayed(run_fold)(train_idx, test_idx) \n",
    "                                           for train_idx, test_idx in loo.split(X_resampled) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f6c6e4-b666-4be8-ae46-84195a90934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOO CV RESULTS\n",
      "======================================================================\n",
      "Accuracy: 0.9938 (99.4%)\n",
      "\n",
      "This is an estimate of performance, but still affected by\n",
      "data leakage since we oversampled before CV.\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        30\n",
      "           5       1.00      1.00      1.00        30\n",
      "           6       1.00      1.00      1.00        30\n",
      "           7       1.00      1.00      1.00        30\n",
      "           8       1.00      1.00      1.00        30\n",
      "           9       1.00      1.00      1.00        30\n",
      "          10       1.00      1.00      1.00        30\n",
      "          11       1.00      1.00      1.00        30\n",
      "          12       1.00      0.90      0.95        30\n",
      "          13       1.00      1.00      1.00        30\n",
      "          14       1.00      1.00      1.00        30\n",
      "          15       0.91      1.00      0.95        30\n",
      "\n",
      "    accuracy                           0.99       480\n",
      "   macro avg       0.99      0.99      0.99       480\n",
      "weighted avg       0.99      0.99      0.99       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unpack results\n",
    "predictions, actuals = zip(*results)\n",
    "\n",
    "# Convert to lists\n",
    "predictions, actuals = list(predictions), list(actuals)\n",
    "\n",
    "# Results\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOO CV RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
    "print(f\"\\nThis is an estimate of performance, but still affected by\")\n",
    "print(f\"data leakage since we oversampled before CV.\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(actuals, predictions, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ae73e-d557-4296-9807-2291774965b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
