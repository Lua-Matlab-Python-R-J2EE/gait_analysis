{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5480bcf3-0e3d-47c8-966f-75acdcf20c47",
   "metadata": {},
   "source": [
    "- GAIT ANALYSIS (Optimized Approach with GridSearchCV, No train/test split) - same as in gait_final_output_v1_2 with R1, R2, R3 transfomed into mean, mediam and std, BUT USING ONLY 107 features at a time either mean, median or mode.\n",
    "\n",
    "- Aim: Multi-class classification to identify subjects (16 individuals) based on gait characteristics, using model comparison and hyperparameter tuning WITHOUT train/test split.\n",
    "\n",
    "- Data Credits: https://archive.ics.uci.edu/dataset/604/gait+classification\n",
    "\n",
    "SUMMARY:\n",
    "- The best performing model is KNeighborsClassifier\n",
    "- mean features: Mean CV Accuracy: 0.8125\n",
    "- median features: Mean CV Accuracy: 0.5416666666666666\n",
    "- std features: Mean CV Accuracy: 0.7083333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dcf0aa1-78d5-4eb5-b62b-bf2945b67692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import LeaveOneOut, LeaveOneGroupOut, StratifiedKFold, GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# these clean up the noisy data\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# these do not clean up the noisy data\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN, SMOTE\n",
    "\n",
    "# avoid as it only duplicates data\n",
    "# from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa664d4-5a6e-41dc-a9b9-5e27dc9ddd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (48, 322)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed_R1</th>\n",
       "      <th>Variability_R1</th>\n",
       "      <th>Symmetry_R1</th>\n",
       "      <th>HeelPressTime_R1</th>\n",
       "      <th>CycleTime_R1</th>\n",
       "      <th>Cadence_R1</th>\n",
       "      <th>Posture_R1</th>\n",
       "      <th>Oscillation_R1</th>\n",
       "      <th>Loading_R1</th>\n",
       "      <th>FootPress_R1</th>\n",
       "      <th>...</th>\n",
       "      <th>P99_R3</th>\n",
       "      <th>P100_R3</th>\n",
       "      <th>P101_R3</th>\n",
       "      <th>P102_R3</th>\n",
       "      <th>P103_R3</th>\n",
       "      <th>P104_R3</th>\n",
       "      <th>P105_R3</th>\n",
       "      <th>P106_R3</th>\n",
       "      <th>P107_R3</th>\n",
       "      <th>Subject_ID_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.34</td>\n",
       "      <td>4.71</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1.132</td>\n",
       "      <td>1.133</td>\n",
       "      <td>1.135</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.316</td>\n",
       "      <td>0.760</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.25</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>1.109</td>\n",
       "      <td>1.109</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1.115</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.165</td>\n",
       "      <td>1.167</td>\n",
       "      <td>1.130</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.214</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Speed_R1  Variability_R1  Symmetry_R1  HeelPressTime_R1  CycleTime_R1  \\\n",
       "22      1.34            4.71         -0.7             1.132         1.133   \n",
       "2       1.25            5.06         -3.8             1.109         1.109   \n",
       "43      1.22            0.00          7.5             1.165         1.167   \n",
       "\n",
       "    Cadence_R1  Posture_R1  Oscillation_R1  Loading_R1  FootPress_R1  ...  \\\n",
       "22       1.135       1.125           0.073       0.053         0.067  ...   \n",
       "2        1.105       1.115           0.048       0.056         0.041  ...   \n",
       "43       1.130       1.130           0.328       0.332         0.040  ...   \n",
       "\n",
       "    P99_R3  P100_R3  P101_R3  P102_R3  P103_R3  P104_R3  P105_R3  P106_R3  \\\n",
       "22   0.024    0.045    0.018    0.057   -0.033    0.208    0.125    1.316   \n",
       "2    0.034    0.048    0.037    0.101    0.056    0.225    0.236    0.989   \n",
       "43   0.026    0.032    0.032    0.098    0.097    0.199    0.230    0.824   \n",
       "\n",
       "    P107_R3  Subject_ID_Y  \n",
       "22    0.760             7  \n",
       "2     1.011             0  \n",
       "43    1.214            14  \n",
       "\n",
       "[3 rows x 322 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('gait_final_output_updated.csv')\n",
    "print(f'df.shape: {df.shape}')\n",
    "print(\"---\")\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00ebdba1-9873-490f-a08d-89fb1c04f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Classes are balanced. Max-to-min count ratio is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "\n",
    "print( df['Subject_ID_Y'].value_counts().to_list() )\n",
    "\n",
    "min_y_count = df['Subject_ID_Y'].value_counts().min()\n",
    "max_y_count = df['Subject_ID_Y'].value_counts().max()\n",
    "\n",
    "if min_y_count/max_y_count > 5: \n",
    "    print(f\"Classes are imbalanced. Max-to-min count ratio is: {min_y_count/max_y_count}\")\n",
    "else:\n",
    "    print(f\"Classes are balanced. Max-to-min count ratio is: {min_y_count/max_y_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ea8ff8-0c0f-4681-8663-9cefc44dc58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mean.shape:(48, 107) | df_median.shape:(48, 107) | df_std.shape:(48, 107)\n"
     ]
    }
   ],
   "source": [
    "# Form a new df, with mean, meadian and mode using df_new\n",
    "\n",
    "cols_to_aggregate, prefixes = [], []\n",
    "\n",
    "# identify columns to aggregate (excluding target)\n",
    "cols_to_aggregate = [col for col in df.columns if col!='Subject_ID_Y']\n",
    "# print( \"cols_to_aggregate:\",cols_to_affregate )\n",
    "\n",
    "# extract unique prefix before the underscore\n",
    "prefixes =  [col.split('_') for col in cols_to_aggregate] \n",
    "# print(\"prefixes:\", prefixes ) # list of lists\n",
    "\n",
    "# create a new dictionary\n",
    "new_columns_mean = {}\n",
    "new_columns_median = {}\n",
    "new_columns_std = {}\n",
    "\n",
    "for prefix in prefixes:\n",
    "    # print(f\"prefix:{prefix} | first_val:{prefix[0]}\")\n",
    "    # find all columns with prefix prefix[0]\n",
    "    # print(\"prefix[0]:\", prefix[0])\n",
    "    matching_cols = [ col for col in cols_to_aggregate if col.startswith( prefix[0] ) ]\n",
    "    # print( \"matching_cols\", matching_cols )    \n",
    "    \n",
    "    if len(matching_cols) <3 :\n",
    "        print(f\"Either the matching_cols list is empty or has less than 3 columns\")    \n",
    "        \n",
    "    elif len(matching_cols) == 3: # we know it has 3 columns, R1, R2, R3\n",
    "        # calculate mean, median and mode\n",
    "        new_columns_mean[f'{prefix[0]}_mean']     = df[matching_cols].mean(axis=1)\n",
    "        new_columns_median[f'{prefix[0]}_median'] = df[matching_cols].median(axis=1)\n",
    "        new_columns_std[f'{prefix[0]}_std']       = df[matching_cols].std(axis=1)\n",
    "        \n",
    "# create a dataframe from this dictionary \n",
    "df_mean   = pd.DataFrame(new_columns_mean)\n",
    "df_median = pd.DataFrame(new_columns_median)\n",
    "df_std    = pd.DataFrame(new_columns_std)\n",
    "\n",
    "print(f\"df_mean.shape:{df_mean.shape} | df_median.shape:{df_median.shape} | df_std.shape:{df_std.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef03859e-9489-44b9-9a01-33575f764646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================iteration i: 1==========================\n",
      "===STEP 0: Split X and y===\n",
      "Total samples: 48\n",
      "Total features: 107\n",
      "Number of classes: 16\n",
      "Class distribution in full dataset:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "===Define oversampler TYPES===\n",
      "min(10, X.shape[1], len(X) // 10) : 4\n",
      "\n",
      "=== smoteenn ===\n",
      "k_neighbors: 2\n",
      "y.value_counts().min(): 3\n",
      "Only 3 samples per class - using RandomOverSampler instead of smoteenn\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "-------end of sampler for loop iter---------\n",
      "\n",
      "=== smotetomek ===\n",
      "k_neighbors: 2\n",
      "y.value_counts().min(): 3\n",
      "Only 3 samples per class - using RandomOverSampler instead of smotetomek\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "-------end of sampler for loop iter---------\n",
      "---------end of execution---------\n",
      "===Print results after the execution ends, nice looking table===\n",
      "       sampler                 model  train_acc  best_cv_score  model_run_time\n",
      "3     smoteenn  KNeighborsClassifier       1.00           0.85           77.32\n",
      "9   smotetomek  KNeighborsClassifier       1.00           0.85           77.16\n",
      "4     smoteenn          RandomForest       1.00           0.83           90.87\n",
      "10  smotetomek          RandomForest       1.00           0.83           90.75\n",
      "1     smoteenn               SVC-RBF       0.96           0.81           27.39\n",
      "7   smotetomek               SVC-RBF       0.75           0.77           26.97\n",
      "8   smotetomek              Logistic       0.77           0.75           35.05\n",
      "2     smoteenn              Logistic       0.85           0.73           35.88\n",
      "0     smoteenn            GaussianNB       0.98           0.60           16.75\n",
      "6   smotetomek            GaussianNB       0.98           0.56           10.36\n",
      "5     smoteenn          DecisionTree       0.75           0.40           76.42\n",
      "11  smotetomek          DecisionTree       0.75           0.40           76.25\n",
      "The above performance is not consistent. However, KNeighborsClassifier with smotetomek is consistently the highest performer.\n",
      "--------------------------------------------------\n",
      "Best param:  {'model__metric': 'minkowski', 'model__n_neighbors': 2, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Best estimator:  Pipeline(steps=[('oversample', RandomOverSampler(random_state=42)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=4,\n",
      "                             score_func=<function mutual_info_classif at 0x78812c5279a0>)),\n",
      "                ('model',\n",
      "                 KNeighborsClassifier(n_neighbors=2, p=1, weights='distance'))])\n",
      "--------------------------------------------------\n",
      "\n",
      "Best params from results: {'model__metric': 'minkowski', 'model__n_neighbors': 2, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Best params from estimator: {'model__metric': 'minkowski', 'model__n_neighbors': 2, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "===Define the best model/params to see if I get the same result===\n",
      "===Use the best_estimator directly===\n",
      "===Fit on your training data & predict output===\n",
      "===Evaluate===\n",
      "Mean CV Accuracy: 0.8125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "==========================iteration i: 2==========================\n",
      "===STEP 0: Split X and y===\n",
      "Total samples: 48\n",
      "Total features: 107\n",
      "Number of classes: 16\n",
      "Class distribution in full dataset:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "===Define oversampler TYPES===\n",
      "min(10, X.shape[1], len(X) // 10) : 4\n",
      "\n",
      "=== smoteenn ===\n",
      "k_neighbors: 2\n",
      "y.value_counts().min(): 3\n",
      "Only 3 samples per class - using RandomOverSampler instead of smoteenn\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "-------end of sampler for loop iter---------\n",
      "\n",
      "=== smotetomek ===\n",
      "k_neighbors: 2\n",
      "y.value_counts().min(): 3\n",
      "Only 3 samples per class - using RandomOverSampler instead of smotetomek\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "-------end of sampler for loop iter---------\n",
      "---------end of execution---------\n",
      "===Print results after the execution ends, nice looking table===\n",
      "       sampler                 model  train_acc  best_cv_score  model_run_time\n",
      "9   smotetomek  KNeighborsClassifier       1.00           0.67           77.11\n",
      "3     smoteenn  KNeighborsClassifier       1.00           0.65           78.74\n",
      "4     smoteenn          RandomForest       0.96           0.62           90.72\n",
      "7   smotetomek               SVC-RBF       0.92           0.58           26.71\n",
      "8   smotetomek              Logistic       0.69           0.58           35.72\n",
      "10  smotetomek          RandomForest       0.90           0.56           90.63\n",
      "1     smoteenn               SVC-RBF       0.83           0.54           27.10\n",
      "2     smoteenn              Logistic       0.79           0.48           36.04\n",
      "6   smotetomek            GaussianNB       0.79           0.35           10.27\n",
      "11  smotetomek          DecisionTree       0.56           0.35           76.50\n",
      "0     smoteenn            GaussianNB       0.94           0.33           10.31\n",
      "5     smoteenn          DecisionTree       0.38           0.31           76.39\n",
      "The above performance is not consistent. However, KNeighborsClassifier with smotetomek is consistently the highest performer.\n",
      "--------------------------------------------------\n",
      "Best param:  {'model__metric': 'manhattan', 'model__n_neighbors': 3, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Best estimator:  Pipeline(steps=[('oversample', RandomOverSampler(random_state=42)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=4,\n",
      "                             score_func=<function mutual_info_classif at 0x78812c5279a0>)),\n",
      "                ('model',\n",
      "                 KNeighborsClassifier(metric='manhattan', n_neighbors=3, p=1,\n",
      "                                      weights='distance'))])\n",
      "--------------------------------------------------\n",
      "\n",
      "Best params from results: {'model__metric': 'manhattan', 'model__n_neighbors': 3, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Best params from estimator: {'model__metric': 'manhattan', 'model__n_neighbors': 3, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "===Define the best model/params to see if I get the same result===\n",
      "===Use the best_estimator directly===\n",
      "===Fit on your training data & predict output===\n",
      "===Evaluate===\n",
      "Mean CV Accuracy: 0.5416666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n",
      "==========================iteration i: 3==========================\n",
      "===STEP 0: Split X and y===\n",
      "Total samples: 48\n",
      "Total features: 107\n",
      "Number of classes: 16\n",
      "Class distribution in full dataset:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "===Define oversampler TYPES===\n",
      "min(10, X.shape[1], len(X) // 10) : 4\n",
      "\n",
      "=== smoteenn ===\n",
      "k_neighbors: 2\n",
      "y.value_counts().min(): 3\n",
      "Only 3 samples per class - using RandomOverSampler instead of smoteenn\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "-------end of sampler for loop iter---------\n",
      "\n",
      "=== smotetomek ===\n",
      "k_neighbors: 2\n",
      "y.value_counts().min(): 3\n",
      "Only 3 samples per class - using RandomOverSampler instead of smotetomek\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "---\n",
      "-------end of model for loop iter---------\n",
      "-------end of sampler for loop iter---------\n",
      "---------end of execution---------\n",
      "===Print results after the execution ends, nice looking table===\n",
      "       sampler                 model  train_acc  best_cv_score  model_run_time\n",
      "3     smoteenn  KNeighborsClassifier       1.00           0.79           76.97\n",
      "9   smotetomek  KNeighborsClassifier       1.00           0.79           77.76\n",
      "7   smotetomek               SVC-RBF       1.00           0.77           26.57\n",
      "10  smotetomek          RandomForest       0.98           0.75           90.63\n",
      "1     smoteenn               SVC-RBF       0.83           0.73           27.12\n",
      "4     smoteenn          RandomForest       0.94           0.73           91.09\n",
      "2     smoteenn              Logistic       0.92           0.69           35.59\n",
      "8   smotetomek              Logistic       0.77           0.67           35.62\n",
      "0     smoteenn            GaussianNB       0.98           0.42           10.25\n",
      "6   smotetomek            GaussianNB       1.00           0.42           10.24\n",
      "5     smoteenn          DecisionTree       0.50           0.35           76.78\n",
      "11  smotetomek          DecisionTree       0.56           0.35           76.92\n",
      "The above performance is not consistent. However, KNeighborsClassifier with smotetomek is consistently the highest performer.\n",
      "--------------------------------------------------\n",
      "Best param:  {'model__metric': 'euclidean', 'model__n_neighbors': 1, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Best estimator:  Pipeline(steps=[('oversample', RandomOverSampler(random_state=42)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=4,\n",
      "                             score_func=<function mutual_info_classif at 0x78812c5279a0>)),\n",
      "                ('model',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=1, p=1,\n",
      "                                      weights='distance'))])\n",
      "--------------------------------------------------\n",
      "\n",
      "Best params from results: {'model__metric': 'euclidean', 'model__n_neighbors': 1, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Best params from estimator: {'model__metric': 'euclidean', 'model__n_neighbors': 1, 'model__p': 1, 'model__weights': 'distance'}\n",
      "--------------------------------------------------\n",
      "===Define the best model/params to see if I get the same result===\n",
      "===Use the best_estimator directly===\n",
      "===Fit on your training data & predict output===\n",
      "===Evaluate===\n",
      "Mean CV Accuracy: 0.7083333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        48\n",
      "   macro avg       1.00      1.00      1.00        48\n",
      "weighted avg       1.00      1.00      1.00        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y =  df['Subject_ID_Y']\n",
    "i = 1\n",
    "\n",
    "for X in [df_mean, df_median, df_std]: \n",
    "    print(f\"==========================iteration i: {i}==========================\")\n",
    "    i += 1\n",
    "    print(\"===STEP 0: Split X and y===\")\n",
    "    \n",
    "    print(f\"Total samples: {len(y)}\")\n",
    "    print(f\"Total features: {X.shape[1]}\")\n",
    "    print(f\"Number of classes: {len(y.unique())}\")\n",
    "    print(f\"Class distribution in full dataset:\")\n",
    "    print(y.value_counts().sort_index().to_list())\n",
    "    \n",
    "    print(\"===Define oversampler TYPES===\")\n",
    "    print( \"min(10, X.shape[1], len(X) // 10) :\",min(10, X.shape[1], len(X) // 10)  )\n",
    "    \n",
    "    oversampler_types = ['smoteenn', 'smotetomek']\n",
    "    oversampler_count = len(oversampler_types)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for key in oversampler_types:\n",
    "        print(f'\\n=== {key} ===')\n",
    "        results[key] = {}\n",
    "        \n",
    "        # Train-test split: NO NO NO\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42 )\n",
    "        # print(\"y_train distribution:\", y_train.value_counts().sort_index().to_list())\n",
    "        \n",
    "        # Get sample counts in train data\n",
    "        n_samples = y.value_counts().min()\n",
    "        k_neighbors = max(1, min(3, n_samples - 1))\n",
    "        print(\"k_neighbors:\", k_neighbors)\n",
    "        print(\"y.value_counts().min():\", n_samples)\n",
    "        \n",
    "        # Choose appropriate oversampler based on sample size\n",
    "        if n_samples < 6:  # Too few samples for SMOTEENN/SMOTETomek\n",
    "            print(f\"Only {n_samples} samples per class - using RandomOverSampler instead of {key}\")\n",
    "            oversampler = RandomOverSampler(random_state=42)\n",
    "        else:\n",
    "            sampling_strategy = {cls: target_samples_per_class for cls in np.unique(y)}\n",
    "            \n",
    "            if key == 'smoteenn':\n",
    "                oversampler = SMOTEENN(\n",
    "                    smote=SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors=k_neighbors),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            elif key == 'smotetomek':\n",
    "                oversampler = SMOTETomek(\n",
    "                    smote=SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors=k_neighbors),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "    \n",
    "        print(\"oversampler used: \", oversampler)\n",
    "    \n",
    "        # Now try differnt models in the pipeline, not just one model.\n",
    "        models = {\n",
    "            'GaussianNB': {\n",
    "                'model': GaussianNB(),\n",
    "                'params': {                \n",
    "                    'var_smoothing': np.logspace(-10, -7, num=4) \n",
    "                }\n",
    "            },\n",
    "            'SVC-RBF': {\n",
    "                'model': SVC(random_state=42, decision_function_shape='ovr'),\n",
    "                'params': {\n",
    "                    'C':      [0.1, 1, 10],\n",
    "                    'gamma':  ['scale', 0.1],\n",
    "                    'kernel': ['rbf', 'linear']\n",
    "                }\n",
    "            },    \n",
    "           'Logistic': {\n",
    "                'model': LogisticRegression(max_iter=1000, random_state=42, multi_class='ovr'),\n",
    "                'params': {\n",
    "                    'C':       [0.01, 0.1, 1, 10],\n",
    "                    'penalty': ['l1', 'l2'],\n",
    "                    'solver':  ['liblinear', 'saga']\n",
    "                    }\n",
    "            },\n",
    "            'KNeighborsClassifier': {\n",
    "                'model': KNeighborsClassifier(),\n",
    "                'params': {\n",
    "                    'n_neighbors':[1, 2, 3],\n",
    "                    'weights':\t  ['uniform', 'distance'],\n",
    "                    'metric':\t  ['euclidean', 'manhattan', 'minkowski'],\n",
    "                    'p':          [1, 2]\n",
    "                    }\n",
    "            },\n",
    "            'RandomForest': {\n",
    "                'model': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                'params': {\n",
    "                    'n_estimators':      [50, 100],        # Not too many\n",
    "                    'max_depth':         [2, 3, 4],        # VERY shallow (key!)\n",
    "                    'min_samples_split': [2, 3, 5],        # Require multiple samples\n",
    "                    'min_samples_leaf':  [1, 2]            # Prevent tiny leaves\n",
    "                    }\n",
    "            },\n",
    "            'DecisionTree': {\n",
    "                'model': DecisionTreeClassifier(random_state=42),\n",
    "                'params': {\n",
    "                    'max_depth':         [2, 3, 4, 5],\n",
    "                    'min_samples_split': [2, 3, 5],\n",
    "                    'min_samples_leaf':  [1, 2, 3]\n",
    "                    }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        \n",
    "        # Check all model's performance\n",
    "        for models_name, models_config in models.items():\n",
    "            print('---')\n",
    "            model_start_time = time.time()\n",
    "                        \n",
    "            # Pipeline        \n",
    "            pipeline = Pipeline([\n",
    "                ('oversample', oversampler),\n",
    "                ('scaler',     StandardScaler()),\n",
    "                ('selector',   SelectKBest(mutual_info_classif, k= min(10, X.shape[1], len(X) // 10) )),\n",
    "                ('model',      models_config['model'] )\n",
    "            ])\n",
    "            param_grid = models_config['params']\n",
    "            \n",
    "            #print(\"param_grid:\", param_grid) \n",
    "            #print( {f'model__{k}': v for k, v in models_config['params'].items()} )\n",
    "            param_grid = {f'model__{k}':v for k,v in models_config['params'].items() } \n",
    "            \n",
    "            # GridSearchCV \n",
    "            cv = StratifiedKFold(n_splits=y.value_counts().min(), shuffle=True, random_state=42)\n",
    "            # n_splits=3 cannot be greater than the number of members in each class.\n",
    "            try:\n",
    "                grid_search = GridSearchCV(\n",
    "                    estimator  = pipeline,\n",
    "                    param_grid = param_grid,\n",
    "                    cv         = cv,\n",
    "                    scoring    = 'accuracy', # can explore this later for precision/recall\n",
    "                    n_jobs     = -1,\n",
    "                    verbose    = 0\n",
    "                )\n",
    "                grid_search.fit(X, y)\n",
    "    \n",
    "                # evaluate\n",
    "                train_acc = grid_search.score(X, y)\n",
    "                #test_acc  = grid_search.score(X_test, y_test)\n",
    "    \n",
    "                results[key][models_name] = {\n",
    "                    'grid'          : grid_search,\n",
    "                    'train_acc'     : train_acc,\n",
    "                    #'test_acc'      : test_acc,\n",
    "                    'best_param'    : grid_search.best_params_,\n",
    "                    'best_estimator': grid_search.best_estimator_,\n",
    "                    'best_cv_score' : grid_search.best_score_,\n",
    "                    'model_run_time': time.time() - model_start_time\n",
    "                }\n",
    "                                \n",
    "            except Exception as e:\n",
    "                print(f\"{models_name} ERROR: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "            print(\"-------end of model for loop iter---------\")\n",
    "        print(\"-------end of sampler for loop iter---------\")\n",
    "    print(\"---------end of execution---------\")\n",
    "        \n",
    "    print(\"===Print results after the execution ends, nice looking table===\")\n",
    "    data = []\n",
    "    for keys, vals in results.items():\n",
    "        for key, val in vals.items():\n",
    "            data.append({\n",
    "                'sampler':       keys,\n",
    "                'model'  :       key,\n",
    "                'train_acc':     round(val['train_acc'],2),\n",
    "                'best_cv_score': round(val['best_cv_score'],2),\n",
    "                'model_run_time':round(val['model_run_time'],2)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data).sort_values(by='best_cv_score', ascending=False)\n",
    "    print( df )\n",
    "    \n",
    "    print(\"The above performance is not consistent. However, KNeighborsClassifier with smotetomek is consistently the highest performer.\")\n",
    "    \n",
    "    # Get the first value in the table\n",
    "    first_sampler = df['sampler'].iloc[0]\n",
    "    first_model   = df['model'].iloc[0]\n",
    "    \n",
    "    # Get the best estimator and params from results\n",
    "    estimator   = results[first_sampler][first_model]['best_estimator']\n",
    "    model_param = results[first_sampler][first_model]['best_param']\n",
    "    \n",
    "    print('-'*50)\n",
    "    print(\"Best param: \", model_param)\n",
    "    print('-'*50)\n",
    "    print(\"\\nBest estimator: \", estimator)\n",
    "    print('-'*50)\n",
    "    \n",
    "    # Verify they match by extracting params from estimator\n",
    "    best_estimator_params = estimator.get_params()\n",
    "    tuned_params = {k: v for k, v in best_estimator_params.items() if k in model_param}\n",
    "    \n",
    "    print(\"\\nBest params from results:\", model_param)\n",
    "    print('-'*50)\n",
    "    print(\"\\nBest params from estimator:\", tuned_params)\n",
    "    print('-'*50)\n",
    "    \n",
    "    print(\"===Define the best model/params to see if I get the same result===\")\n",
    "    \n",
    "    print(\"===Use the best_estimator directly===\")\n",
    "    best_pipeline = results[first_sampler][first_model]['best_estimator']\n",
    "    \n",
    "    print(\"===Fit on your training data & predict output===\")\n",
    "    best_pipeline.fit(X, y)\n",
    "    y_pred = best_pipeline.predict(X)\n",
    "    \n",
    "    print(\"===Evaluate===\")       \n",
    "    cv_accuracy = cross_val_score(\n",
    "        estimator = best_pipeline, \n",
    "        X=X,\n",
    "        y=y, \n",
    "        scoring='accuracy',\n",
    "        cv=cv\n",
    "    )\n",
    "    print('Mean CV Accuracy:', cv_accuracy.mean())\n",
    "    \n",
    "    report = classification_report(y, y_pred)\n",
    "    print(report)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3eaf0-39aa-4101-a3bb-9aafe276b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be86fe-7f9e-4bd0-949d-43786d2df9e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651751f-f6cb-4d6d-8cb6-211d8b6ccb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
