{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5480bcf3-0e3d-47c8-966f-75acdcf20c47",
   "metadata": {},
   "source": [
    "Gait Analysis (baseline approach (as in gait_final_output_v1_1_modified_features.ipynb) with R1, R2, R3 transfomed into mean, mediam and std, BUT USING ONLY 107 features at a time either mean, median or mode)\n",
    "\n",
    "Aim: \n",
    "- Multi-class classification (16 subjects) using train/test split with SMOTE-based oversampling in pipeline - the first attempt/baseline approach.\n",
    "\n",
    "Data Source/Credit: \n",
    "- https://archive.ics.uci.edu/dataset/604/gait+classification\n",
    "\n",
    "Dataset\n",
    "- Size:         48 samples (16 subjects * 3 trials)\n",
    "- Features:     Transformed features into mean, median and mode for R1, R2 and R3 to derive new 321 features and use those for classification. ONLY 107 USED AT A TIME (EITHER MEAN/MEDIAN/MODE)\n",
    "- Target:       Subject identification (16 classes)\n",
    "- Missing data: 1 NA value in CycleTime_R2 (imputed with median)\n",
    "- Split:        67% train / 33% test -> ~2 training samples/class + 1 test sample/class \n",
    "\n",
    "Conclusion from this analysis: \n",
    "- same performance as gait_final_output_v1_1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2e62606-7b54-4233-bb84-9090b1662aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcf0aa1-78d5-4eb5-b62b-bf2945b67692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import LeaveOneOut, LeaveOneGroupOut, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# these clean up the noisy data\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# these do not clean up the noisy data\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN, SMOTE\n",
    "\n",
    "# avoid as it only duplicates data\n",
    "# from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa664d4-5a6e-41dc-a9b9-5e27dc9ddd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (48, 322)\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed_R1</th>\n",
       "      <th>Variability_R1</th>\n",
       "      <th>Symmetry_R1</th>\n",
       "      <th>HeelPressTime_R1</th>\n",
       "      <th>CycleTime_R1</th>\n",
       "      <th>Cadence_R1</th>\n",
       "      <th>Posture_R1</th>\n",
       "      <th>Oscillation_R1</th>\n",
       "      <th>Loading_R1</th>\n",
       "      <th>FootPress_R1</th>\n",
       "      <th>...</th>\n",
       "      <th>P99_R3</th>\n",
       "      <th>P100_R3</th>\n",
       "      <th>P101_R3</th>\n",
       "      <th>P102_R3</th>\n",
       "      <th>P103_R3</th>\n",
       "      <th>P104_R3</th>\n",
       "      <th>P105_R3</th>\n",
       "      <th>P106_R3</th>\n",
       "      <th>P107_R3</th>\n",
       "      <th>Subject_ID_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>1.114</td>\n",
       "      <td>1.093</td>\n",
       "      <td>1.045</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.153</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.32</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.169</td>\n",
       "      <td>1.113</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1.113</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.167</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>1.128</td>\n",
       "      <td>1.146</td>\n",
       "      <td>1.075</td>\n",
       "      <td>1.080</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.090</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Speed_R1  Variability_R1  Symmetry_R1  HeelPressTime_R1  CycleTime_R1  \\\n",
       "11      1.58            0.00         -7.4             1.114         1.093   \n",
       "30      1.32            6.19          1.9             1.169         1.113   \n",
       "37      1.26            0.00         -3.2             1.128         1.146   \n",
       "\n",
       "    Cadence_R1  Posture_R1  Oscillation_R1  Loading_R1  FootPress_R1  ...  \\\n",
       "11       1.045       1.035           0.560       0.401         0.055  ...   \n",
       "30       1.105       1.113           0.461       0.069         0.073  ...   \n",
       "37       1.075       1.080           0.421       0.597         0.056  ...   \n",
       "\n",
       "    P99_R3  P100_R3  P101_R3  P102_R3  P103_R3  P104_R3  P105_R3  P106_R3  \\\n",
       "11   0.015    0.035    0.019    0.105    0.162    0.213    0.227    0.867   \n",
       "30   0.015    0.027    0.021    0.125    0.160    0.207    0.224    0.857   \n",
       "37   0.012    0.028    0.018    0.060    0.105    0.170    0.171    0.918   \n",
       "\n",
       "    P107_R3  Subject_ID_Y  \n",
       "11    1.153             3  \n",
       "30    1.167            10  \n",
       "37    1.090            12  \n",
       "\n",
       "[3 rows x 322 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('gait_final_output_updated.csv')\n",
    "print(f'df.shape: {df.shape}')\n",
    "print(\"---\")\n",
    "df.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ea8ff8-0c0f-4681-8663-9cefc44dc58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Classes are balanced. Max-to-min count ratio is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "\n",
    "print( df['Subject_ID_Y'].value_counts().to_list() )\n",
    "\n",
    "min_y_count = df['Subject_ID_Y'].value_counts().min()\n",
    "max_y_count = df['Subject_ID_Y'].value_counts().max()\n",
    "\n",
    "if min_y_count/max_y_count > 5: \n",
    "    print(f\"Classes are imbalanced. Max-to-min count ratio is: {min_y_count/max_y_count}\")\n",
    "else:\n",
    "    print(f\"Classes are balanced. Max-to-min count ratio is: {min_y_count/max_y_count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee93b600-fcef-4a89-8d41-0e81cae01d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mean.shape:(48, 107) | df_median.shape:(48, 107) | df_std.shape:(48, 107)\n"
     ]
    }
   ],
   "source": [
    "# Form a new df, with mean, meadian and mode using df_new\n",
    "\n",
    "cols_to_aggregate, prefixes = [], []\n",
    "\n",
    "# identify columns to aggregate (excluding target)\n",
    "cols_to_aggregate = [col for col in df.columns if col!='Subject_ID_Y']\n",
    "# print( \"cols_to_aggregate:\",cols_to_affregate )\n",
    "\n",
    "# extract unique prefix before the underscore\n",
    "prefixes =  [col.split('_') for col in cols_to_aggregate] \n",
    "# print(\"prefixes:\", prefixes ) # list of lists\n",
    "\n",
    "# create a new dictionary\n",
    "new_columns_mean = {}\n",
    "new_columns_median = {}\n",
    "new_columns_std = {}\n",
    "\n",
    "for prefix in prefixes:\n",
    "    # print(f\"prefix:{prefix} | first_val:{prefix[0]}\")\n",
    "    # find all columns with prefix prefix[0]\n",
    "    # print(\"prefix[0]:\", prefix[0])\n",
    "    matching_cols = [ col for col in cols_to_aggregate if col.startswith( prefix[0] ) ]\n",
    "    # print( \"matching_cols\", matching_cols )    \n",
    "    \n",
    "    if len(matching_cols) <3 :\n",
    "        print(f\"Either the matching_cols list is empty or has less than 3 columns\")    \n",
    "        \n",
    "    elif len(matching_cols) == 3: # we know it has 3 columns, R1, R2, R3\n",
    "        # calculate mean, median and mode\n",
    "        new_columns_mean[f'{prefix[0]}_mean']     = df[matching_cols].mean(axis=1)\n",
    "        new_columns_median[f'{prefix[0]}_median'] = df[matching_cols].median(axis=1)\n",
    "        new_columns_std[f'{prefix[0]}_std']       = df[matching_cols].std(axis=1)\n",
    "        \n",
    "# create a dataframe from this dictionary \n",
    "df_mean   = pd.DataFrame(new_columns_mean)\n",
    "df_median = pd.DataFrame(new_columns_median)\n",
    "df_std    = pd.DataFrame(new_columns_std)\n",
    "\n",
    "print(f\"df_mean.shape:{df_mean.shape} | df_median.shape:{df_median.shape} | df_std.shape:{df_std.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c8688c6-9e33-4387-b2a4-bf00c200d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Total samples: 48\n",
      "Total features: 107\n",
      "Number of classes: 16\n",
      "Class distribution in full dataset:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "\n",
      "=== smoteenn ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smoteenn\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.20      1.00      0.33         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.36      0.50      0.40        16\n",
      "weighted avg       0.36      0.50      0.40        16\n",
      "\n",
      "\n",
      "=== smotetomek ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smotetomek\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.14      1.00      0.25         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       0.50      1.00      0.67         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.32      0.44      0.35        16\n",
      "weighted avg       0.32      0.44      0.35        16\n",
      "\n",
      "--------------------------------------------------\n",
      "Total samples: 48\n",
      "Total features: 107\n",
      "Number of classes: 16\n",
      "Class distribution in full dataset:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "\n",
      "=== smoteenn ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smoteenn\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.12      1.00      0.22         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.50      1.00      0.67         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.13      0.25      0.16        16\n",
      "weighted avg       0.13      0.25      0.16        16\n",
      "\n",
      "\n",
      "=== smotetomek ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smotetomek\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.33      1.00      0.50         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.14      1.00      0.25         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.50      1.00      0.67         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.12      0.25      0.15        16\n",
      "weighted avg       0.12      0.25      0.15        16\n",
      "\n",
      "--------------------------------------------------\n",
      "Total samples: 48\n",
      "Total features: 107\n",
      "Number of classes: 16\n",
      "Class distribution in full dataset:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "\n",
      "=== smoteenn ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smoteenn\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.25      1.00      0.40         1\n",
      "           3       0.20      1.00      0.33         1\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.15      0.25      0.17        16\n",
      "weighted avg       0.15      0.25      0.17        16\n",
      "\n",
      "\n",
      "=== smotetomek ===\n",
      "y_train distribution: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "k_neighbors: 1\n",
      "y_train.value_counts().min(): 2\n",
      "Only 2 samples per class - using RandomOverSampler instead of smotetomek\n",
      "oversampler used:  RandomOverSampler(random_state=42)\n",
      "Skipping cross-validation - only 2 samples per class\n",
      "Training on training set and evaluating on test set only...\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.25      1.00      0.40         1\n",
      "           3       0.20      1.00      0.33         1\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.25        16\n",
      "   macro avg       0.15      0.25      0.17        16\n",
      "weighted avg       0.15      0.25      0.17        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 0: Split X and y\n",
    "\n",
    "y =  df['Subject_ID_Y']\n",
    "\n",
    "for X in [df_mean, df_median, df_std]:\n",
    "    # print(f\"processing: {X}\") # process each dataframe one by one\n",
    "    print('-'*50)\n",
    "    print(f\"Total samples: {len(y)}\")\n",
    "    print(f\"Total features: {X.shape[1]}\")\n",
    "    print(f\"Number of classes: {len(y.unique())}\")\n",
    "    print(f\"Class distribution in full dataset:\")\n",
    "    print(y.value_counts().sort_index().to_list())\n",
    "    \n",
    "    # Define oversampler TYPES\n",
    "    oversampler_types = ['smoteenn', 'smotetomek']\n",
    "    oversampler_count = len(oversampler_types)\n",
    "    \n",
    "    for key in oversampler_types:\n",
    "        print(f'\\n=== {key} ===')\n",
    "        \n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42 )\n",
    "        print(\"y_train distribution:\", y_train.value_counts().sort_index().to_list())\n",
    "        \n",
    "        # Get sample counts in train data\n",
    "        n_samples = y_train.value_counts().min()\n",
    "        k_neighbors = max(1, min(3, n_samples - 1))\n",
    "        print(\"k_neighbors:\", k_neighbors)\n",
    "        print(\"y_train.value_counts().min():\", n_samples)\n",
    "        \n",
    "        # Choose appropriate oversampler based on sample size\n",
    "        if n_samples < 6:  # Too few samples for SMOTEENN/SMOTETomek\n",
    "            print(f\"Only {n_samples} samples per class - using RandomOverSampler instead of {key}\")\n",
    "            oversampler = RandomOverSampler(random_state=42)\n",
    "        else:\n",
    "            sampling_strategy = {cls: target_samples_per_class for cls in np.unique(y_train)}\n",
    "            \n",
    "            if key == 'smoteenn':\n",
    "                oversampler = SMOTEENN(\n",
    "                    smote=SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors=k_neighbors),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "            elif key == 'smotetomek':\n",
    "                oversampler = SMOTETomek(\n",
    "                    smote=SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors=k_neighbors),\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "    \n",
    "        print(\"oversampler used: \", oversampler)    \n",
    "        \n",
    "        # Pipeline with GaussianNB\n",
    "        max_k = min(10, X_train.shape[1], len(X_train) // 10)\n",
    "        pipeline = Pipeline([\n",
    "            ('oversample', oversampler),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('selector', SelectKBest(mutual_info_classif, k=max_k)),\n",
    "            ('model', GaussianNB())\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            # Check if we have enough samples for cross-validation\n",
    "            if n_samples < 3:\n",
    "                print(f\"Skipping cross-validation - only {n_samples} samples per class\")\n",
    "                print(\"Training on training set and evaluating on test set only...\")\n",
    "                \n",
    "                # Just fit on training data and evaluate on test\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                y_pred_test = pipeline.predict(X_test)\n",
    "                \n",
    "                print(\"\\nTest Report:\")\n",
    "                print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "            else:\n",
    "                # Cross-validation\n",
    "                n_splits = min(5, n_samples)\n",
    "                cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "                \n",
    "                y_pred_train = cross_val_predict(pipeline, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "                print(\"\\nTraining CV Report:\")\n",
    "                print(classification_report(y_train, y_pred_train, zero_division=0))\n",
    "                \n",
    "                # Final evaluation\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                y_pred_test = pipeline.predict(X_test)\n",
    "                print(\"\\nTest Report:\")\n",
    "                print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "    \n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"Error with {key}: {e}\")\n",
    "            print(\"Debug info:\")\n",
    "            print(f\"  - X_train shape: {X_train.shape}\")\n",
    "            print(f\"  - y_train distribution: {y_train.value_counts().to_dict()}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d5a97-df9b-416a-900f-cf0b3cf70d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57be86fe-7f9e-4bd0-949d-43786d2df9e9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103032aa-61ed-45a1-b029-04f2d69c5df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
