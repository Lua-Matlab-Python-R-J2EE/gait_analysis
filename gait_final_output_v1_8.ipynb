{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb87a4f-59d3-46d3-a1f2-85bd1c0ad71e",
   "metadata": {},
   "source": [
    "Gait Analysis (Train/Test Split with Proper Pipeline Oversampling)\n",
    "\n",
    "Aim: Multi-class classification (16 subjects) using a train/test split with oversampling inside the pipeline to avoid data leakage.\n",
    "\n",
    "Data Source: UCI Machine Learning Repository – Gait Classification Dataset\n",
    "\n",
    "Dataset\n",
    "- Original: 48 samples (16 subjects, 3 samples/class)\n",
    "- Train Set: ~31 samples (65%) => ~2 samples per class\n",
    "- Test Set: ~17 samples (35%) => ~1 sample per class\n",
    "- Split: Stratified to ensure all classes are represented\n",
    "  \n",
    "Key Strategy: Oversampling inside the pipeline (after split)\n",
    "- Step 1: Split data (65/35 stratified)\n",
    "- Step 2: Pipeline applies oversampling only to training data\n",
    "- No data leakage: Test set remains original, unmodified\n",
    "\n",
    "Pipeline Components\n",
    "- StandardScaler: Feature normalization\n",
    "- RandomOverSampler: Class balancing (applied only to training)\n",
    "- SelectKBest: Feature selection (tested k = 2, 3, 4, 5, 10, 15)\n",
    "- SVC: RBF kernel classifier\n",
    "\n",
    "Results\n",
    "- Best Performance: k=10 features, 88.2% accuracy\n",
    "- Observation: Complete failure on few subjects (0% precision/recall)\n",
    "\n",
    "What This Approach Gets Right \n",
    "- No data leakage: Oversampling only on training data (via pipeline)\n",
    "- Stratified split: All classes represented in train/test\n",
    "- Feature selection: Tests multiple k values to find optimal subset\n",
    "- Meaningful result: 88.2% accuracy with proper train/test separation\n",
    "- Demonstrates correct ML workflow: Model learns discriminative features\n",
    "\n",
    "Critical Limitations\n",
    "- Not Person-Independent\n",
    "    - Training: All 16 subjects (samples 1–2)\n",
    "    - Test: All 16 subjects (sample 3)\n",
    "    - Problem: Model learns to recognize known individuals, not new ones\n",
    "    - Model sees all subjects during training -> cannot generalize to unseen people\n",
    "- Extremely Unstable Evaluation\n",
    "    - Only 1 test sample per class -> one misclassification = 100% error\n",
    "    - Few subjects/classes: 0% precision/recall (complete failure)\n",
    "    - High variance: Results are highly sensitive to individual predictions\n",
    "\n",
    "- Single Random Split Dependency\n",
    "    - Results vary drastically based on random split: random_state=42 (88.2% accuracy), random_state=43 (potentially different results)\n",
    "    - No averaging across multiple splits\n",
    "    - Cannot assess performance stability\n",
    "\n",
    "Comparison: StratifiedKFold vs Train/Test Split\n",
    "- This approach uses a train/test split with a single random split \n",
    "- Train/test split is inferior to StratifiedKFold for tiny datasets because:\n",
    "    - Data utilization: StratifiedKFold uses all 48 samples (no waste), while this approach wastes 17 samples (only for testing)\n",
    "    - Stability: StratifiedKFold averages results across folds (more stable), while this approach has high variance due to a single split\n",
    "    - Reliability: StratifiedKFold provides more robust estimates with multiple evaluation points\n",
    "\n",
    "Valid Interpretations \n",
    "- Session classification: Can distinguish different walking sessions of known subjects\n",
    "- Intra-subject variability: How consistent gait features are across recordings\n",
    "- Feature discriminability: Features contain subject-specific information\n",
    "- Pipeline correctness: Proper implementation without data leakage\n",
    "\n",
    "Invalid Interpretations\n",
    "- Biometric identification: Cannot identify new/unseen people\n",
    "- Deployment readiness: Not ready for real-world identification system\n",
    "- Person-independent performance: Doesn't test recognition of strangers\n",
    "- Stable estimates: Single split with 1 test sample/class is unreliable\n",
    "\n",
    "Valid Applications\n",
    "- Drift detection: Identifying changes in known subjects' gait over time\n",
    "- Session authentication: Verifying same person across different sessions\n",
    "- Feature engineering: Understanding which features work best\n",
    "- Algorithm comparison: Comparing different models on same task\n",
    "\n",
    "Invalid Applications\n",
    "- New person identification: Cannot recognize people not in training set\n",
    "- Security/access control: Not suitable for biometric authentication\n",
    "- Forensic applications: Cannot identify unknown individuals\n",
    "- Medical diagnosis: Cannot generalize to new patient populations\n",
    "\n",
    "Key Lessons\n",
    "- This approach correctly implements ML methodology (no data leakage, proper pipeline), but is inferior to StratifiedKFold for tiny datasets due to:\n",
    "    - Unstable evaluation (1 test sample per class)\n",
    "    - Data waste (17 samples only for testing)\n",
    "    - High variance (single random split)\n",
    "    - Complete failure on some subjects (0% precision/recall)\n",
    "\n",
    "- Both approaches share a fundamental limitation: \n",
    "    - Neither is person-independent. \n",
    "    - Both test on different samples from subjects already seen during training.\n",
    "\n",
    "For this dataset: \n",
    "- StratifiedKFold with pipeline oversampling is the better approach because it maximizes data usage AND provides more stable estimates\n",
    "- 88.2% accuracy shows features are discriminative, but represents within-subject recognition (different sessions of same people), not cross-subject identification (recognizing new people). \n",
    "- The unstable results for few classes (complete failures) confirm that 3 samples/class is insufficient for reliable train/test split evaluation.\n",
    "\n",
    "Summary\n",
    "- Sound methodologically for testing intra-subject discrimination (can features distinguish known subjects?)\n",
    "- Not sound for inter-subject generalization (can the model identify unseen individuals?).\n",
    "- It validates feature discriminability and pattern consistency, but not real-world generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28835b7-4dec-47cc-b334-c5a48692944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from imblearn.pipeline import Pipeline      \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f84b728-c84e-47ed-9a80-39141c52dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0, k:2, accuracy:0.47058823529411764\n",
      "i:1, k:3, accuracy:0.4117647058823529\n",
      "i:2, k:4, accuracy:0.47058823529411764\n",
      "i:3, k:5, accuracy:0.6470588235294118\n",
      "i:4, k:10, accuracy:0.8823529411764706\n",
      "i:5, k:15, accuracy:0.7058823529411765\n",
      "best_idx: 4\n",
      "==================================================\n",
      "Classification report for best accuracy at k=10, accuracy:0.8823529411764706\n",
      "('              precision    recall  f1-score   support\\n'\n",
      " '\\n'\n",
      " '           0       1.00      1.00      1.00         1\\n'\n",
      " '           1       0.00      0.00      0.00         1\\n'\n",
      " '           2       1.00      1.00      1.00         1\\n'\n",
      " '           3       1.00      1.00      1.00         1\\n'\n",
      " '           4       0.50      1.00      0.67         1\\n'\n",
      " '           5       1.00      1.00      1.00         1\\n'\n",
      " '           6       1.00      1.00      1.00         2\\n'\n",
      " '           7       0.50      1.00      0.67         1\\n'\n",
      " '           8       1.00      1.00      1.00         1\\n'\n",
      " '           9       1.00      1.00      1.00         1\\n'\n",
      " '          10       1.00      1.00      1.00         1\\n'\n",
      " '          11       0.00      0.00      0.00         1\\n'\n",
      " '          12       1.00      1.00      1.00         1\\n'\n",
      " '          13       1.00      1.00      1.00         1\\n'\n",
      " '          14       1.00      1.00      1.00         1\\n'\n",
      " '          15       1.00      1.00      1.00         1\\n'\n",
      " '\\n'\n",
      " '    accuracy                           0.88        17\\n'\n",
      " '   macro avg       0.81      0.88      0.83        17\\n'\n",
      " 'weighted avg       0.82      0.88      0.84        17\\n')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.read_csv(\"gait_final_output_updated.csv\")\n",
    "\n",
    "X = df_new.drop(columns=['Subject_ID_Y'])\n",
    "y = df_new['Subject_ID_Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.35,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "accuracy = {}\n",
    "\n",
    "k_vals = [2, 3, 4, 5, 10, 15]\n",
    "for k in k_vals:\n",
    "    accuracy[k] = {}\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"oversample\", RandomOverSampler()),\n",
    "        (\"feature_selector\", SelectKBest(mutual_info_classif, k=k)),\n",
    "        (\"clf\", SVC(kernel='rbf'))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "    accuracy[k]['score'] =  score\n",
    "    accuracy[k]['report']   =  classification_report(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # pprint.pprint(\"accuracy: \", accuracy)\n",
    "    \n",
    "best_acc = []\n",
    "for i, k in enumerate(k_vals):\n",
    "    print(f\"i:{i}, k:{k}, accuracy:{accuracy[k]['score']}\" )\n",
    "    best_acc.append( accuracy[k]['score'] )\n",
    "\n",
    "best_idx = np.argmax(best_acc)\n",
    "print(\"best_idx:\", best_idx)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"Classification report for best accuracy at k={ k_vals[best_idx] }, accuracy:{accuracy[ k_vals[best_idx] ]['score']}\" )\n",
    "pprint.pprint( accuracy[ k_vals[best_idx] ]['report'] )\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504e3d0-8507-4c50-bd6c-490f77321e48",
   "metadata": {},
   "source": [
    "CONCLUSION: \n",
    "- (StratefiedKFold + No data split) is BETTER than (No StratefiedKFold + Data split)\n",
    "    - This is bec in latter we see precision/recall = 0.0 \n",
    "- With k=10 features fro SelectKBest perform consistently well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36f778-8fff-4912-92ad-340c9fe997d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
