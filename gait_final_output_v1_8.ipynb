{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb87a4f-59d3-46d3-a1f2-85bd1c0ad71e",
   "metadata": {},
   "source": [
    "Gait Analysis (Train/Test Split with Proper Pipeline Oversampling)\n",
    "\n",
    "Aim: Multi-class classification (16 subjects) using a train/test split with oversampling inside the pipeline to avoid data leakage.\n",
    "\n",
    "Data Source: UCI Machine Learning Repository – Gait Classification Dataset\n",
    "\n",
    "Dataset\n",
    "- Original: 48 samples (16 subjects, 3 samples/class)\n",
    "- Train Set: ~31 samples (65%) => ~2 samples per class\n",
    "- Test Set: ~17 samples (35%) => ~1 sample per class\n",
    "- Split: Stratified to ensure all classes are represented\n",
    "  \n",
    "Key Strategy: Oversampling inside the pipeline (after split)\n",
    "- Step 1: Split data (65/35 stratified)\n",
    "- Step 2: Pipeline applies oversampling only to training data\n",
    "- No data leakage: Test set remains original, unmodified\n",
    "\n",
    "Pipeline Components\n",
    "- StandardScaler: Feature normalization\n",
    "- RandomOverSampler: Class balancing (applied only to training)\n",
    "- SelectKBest: Feature selection (tested k = 2, 3, 4, 5, 10, 15)\n",
    "- SVC: RBF kernel classifier\n",
    "\n",
    "Results\n",
    "- Best Performance: k=10 features, 88.2% accuracy\n",
    "- Observation: Complete failure on few subjects (0% precision/recall)\n",
    "\n",
    "What This Approach Gets Right \n",
    "- No data leakage: Oversampling only on training data (via pipeline)\n",
    "- Stratified split: All classes represented in train/test\n",
    "- Feature selection: Tests multiple k values to find optimal subset\n",
    "- Meaningful result: 88.2% accuracy with proper train/test separation\n",
    "- Demonstrates correct ML workflow: Model learns discriminative features\n",
    "\n",
    "Critical Limitations\n",
    "- Not Person-Independent\n",
    "    - Training: All 16 subjects (samples 1–2)\n",
    "    - Test: All 16 subjects (sample 3)\n",
    "    - Problem: Model learns to recognize known individuals, not new ones\n",
    "    - Model sees all subjects during training -> cannot generalize to unseen people\n",
    "- Extremely Unstable Evaluation\n",
    "    - Only 1 test sample per class -> one misclassification = 100% error\n",
    "    - Few subjects/classes: 0% precision/recall (complete failure)\n",
    "    - High variance: Results are highly sensitive to individual predictions\n",
    "\n",
    "- Single Random Split Dependency\n",
    "    - Results vary drastically based on random split: random_state=42 (88.2% accuracy), random_state=43 (potentially different results)\n",
    "    - No averaging across multiple splits\n",
    "    - Cannot assess performance stability\n",
    "\n",
    "Comparison: StratifiedKFold vs Train/Test Split\n",
    "- This approach uses a train/test split with a single random split \n",
    "- Train/test split is inferior to StratifiedKFold for tiny datasets because:\n",
    "    - Data utilization: StratifiedKFold uses all 48 samples (no waste), while this approach wastes 17 samples (only for testing)\n",
    "    - Stability: StratifiedKFold averages results across folds (more stable), while this approach has high variance due to a single split\n",
    "    - Reliability: StratifiedKFold provides more robust estimates with multiple evaluation points\n",
    "\n",
    "Valid Interpretations \n",
    "- Session classification: Can distinguish different walking sessions of known subjects\n",
    "- Intra-subject variability: How consistent gait features are across recordings\n",
    "- Feature discriminability: Features contain subject-specific information\n",
    "- Pipeline correctness: Proper implementation without data leakage\n",
    "\n",
    "Invalid Interpretations\n",
    "- Biometric identification: Cannot identify new/unseen people\n",
    "- Deployment readiness: Not ready for real-world identification system\n",
    "- Person-independent performance: Doesn't test recognition of strangers\n",
    "- Stable estimates: Single split with 1 test sample/class is unreliable\n",
    "\n",
    "Valid Applications\n",
    "- Drift detection: Identifying changes in known subjects' gait over time\n",
    "- Session authentication: Verifying same person across different sessions\n",
    "- Feature engineering: Understanding which features work best\n",
    "- Algorithm comparison: Comparing different models on same task\n",
    "\n",
    "Invalid Applications\n",
    "- New person identification: Cannot recognize people not in training set\n",
    "- Security/access control: Not suitable for biometric authentication\n",
    "- Forensic applications: Cannot identify unknown individuals\n",
    "- Medical diagnosis: Cannot generalize to new patient populations\n",
    "\n",
    "Key Lessons\n",
    "- This approach correctly implements ML methodology (no data leakage, proper pipeline), but is inferior to StratifiedKFold for tiny datasets due to:\n",
    "    - Unstable evaluation (1 test sample per class)\n",
    "    - Data waste (17 samples only for testing)\n",
    "    - High variance (single random split)\n",
    "    - Complete failure on some subjects (0% precision/recall)\n",
    "\n",
    "- Both approaches share a fundamental limitation: \n",
    "    - Neither is person-independent. \n",
    "    - Both test on different samples from subjects already seen during training.\n",
    "\n",
    "For this dataset: \n",
    "- StratifiedKFold with pipeline oversampling is the better approach because it maximizes data usage AND provides more stable estimates\n",
    "- 88.2% accuracy shows features are discriminative, but represents within-subject recognition (different sessions of same people), not cross-subject identification (recognizing new people). \n",
    "- The unstable results for few classes (complete failures) confirm that 3 samples/class is insufficient for reliable train/test split evaluation.\n",
    "\n",
    "Summary\n",
    "- Sound methodologically for testing intra-subject discrimination (can features distinguish known subjects?)\n",
    "- Not sound for inter-subject generalization (can the model identify unseen individuals?).\n",
    "- It validates feature discriminability and pattern consistency, but not real-world generalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d28835b7-4dec-47cc-b334-c5a48692944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from imblearn.pipeline import Pipeline      \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f84b728-c84e-47ed-9a80-39141c52dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing with random_state=42\n",
      "==================================================\n",
      "Best k for this split: 10 (accuracy: 0.706)\n",
      "\n",
      "==================================================\n",
      "Testing with random_state=123\n",
      "==================================================\n",
      "Best k for this split: 15 (accuracy: 0.882)\n",
      "\n",
      "==================================================\n",
      "Testing with random_state=456\n",
      "==================================================\n",
      "Best k for this split: 10 (accuracy: 0.824)\n",
      "\n",
      "==================================================\n",
      "Testing with random_state=789\n",
      "==================================================\n",
      "Best k for this split: 4 (accuracy: 0.824)\n",
      "\n",
      "==================================================\n",
      "Testing with random_state=101112\n",
      "==================================================\n",
      "Best k for this split: 4 (accuracy: 0.882)\n"
     ]
    }
   ],
   "source": [
    "# Tests multiple train/test splits (5 different random states)\n",
    "# Finds which k value is most stable across splits (either most frequently best, or highest mean accuracy)\n",
    "# Uses that k value to train final model with random_state=42\n",
    "# Extracts feature names for that final model\n",
    "\n",
    "df_new = pd.read_csv(\"gait_final_output_updated.csv\")\n",
    "X = df_new.drop(columns=['Subject_ID_Y'])\n",
    "y = df_new['Subject_ID_Y']\n",
    "\n",
    "k_vals = [2, 3, 4, 5, 10, 15]\n",
    "random_states = [42, 123, 456, 789, 101112]  # Test 5 different splits\n",
    "\n",
    "# Store results across all random states\n",
    "all_results = {k: [] for k in k_vals}\n",
    "best_k_per_state = []\n",
    "\n",
    "for rs in random_states:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Testing with random_state={rs}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.35,\n",
    "        stratify=y,\n",
    "        random_state=rs\n",
    "    )\n",
    "    \n",
    "    accuracy = {}\n",
    "    \n",
    "    for k in k_vals:\n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"oversample\", RandomOverSampler(random_state=42)),\n",
    "            (\"feature_selector\", SelectKBest(mutual_info_classif, k=k)),\n",
    "            (\"clf\", SVC(kernel='rbf', random_state=42))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)    \n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        accuracy[k] = {\n",
    "            'score': score,\n",
    "            'report': classification_report(y_test, y_pred, zero_division=0),\n",
    "            'pipeline': pipeline\n",
    "        }\n",
    "        \n",
    "        all_results[k].append(score)\n",
    "    \n",
    "    # Find best k for this random state\n",
    "    best_k_this_state = max(accuracy.keys(), key=lambda k: accuracy[k]['score'])\n",
    "    best_k_per_state.append(best_k_this_state)\n",
    "    print(f\"Best k for this split: {best_k_this_state} (accuracy: {accuracy[best_k_this_state]['score']:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dac4377-033b-45ed-aac0-98d134a4a1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SUMMARY ACROSS ALL RANDOM STATES\n",
      "==================================================\n",
      "k=2: mean=0.529, std=0.153, scores=['0.412', '0.588', '0.294', '0.706', '0.647']\n",
      "k=3: mean=0.471, std=0.207, scores=['0.118', '0.529', '0.471', '0.471', '0.765']\n",
      "k=4: mean=0.729, std=0.109, scores=['0.647', '0.588', '0.706', '0.824', '0.882']\n",
      "k=5: mean=0.718, std=0.101, scores=['0.588', '0.647', '0.706', '0.765', '0.882']\n",
      "k=10: mean=0.765, std=0.053, scores=['0.706', '0.824', '0.824', '0.706', '0.765']\n",
      "k=15: mean=0.706, std=0.158, scores=['0.412', '0.882', '0.765', '0.706', '0.765']\n",
      "\n",
      "Most frequently best k: 10 (selected 2/5 times)\n",
      "k with highest mean accuracy: 10 (mean=0.765)\n",
      "\n",
      "==================================================\n",
      "FINAL RECOMMENDATION: k=10\n",
      "==================================================\n",
      "\n",
      "Final model performance (random_state=42):\n",
      "Accuracy: 0.647\n",
      "\n",
      "Top 10 features selected:\n",
      "  1. P33_R1\n",
      "  2. P81_R1\n",
      "  3. P83_R2\n",
      "  4. Posture_R3\n",
      "  5. Loading_R3\n",
      "  6. P52_R3\n",
      "  7. P53_R3\n",
      "  8. P55_R3\n",
      "  9. P66_R3\n",
      "  10. P68_R3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.33      1.00      0.50         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.50      1.00      0.67         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.55      0.62      0.57        17\n",
      "weighted avg       0.58      0.65      0.60        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze results across all random states\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY ACROSS ALL RANDOM STATES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for k in k_vals:\n",
    "    scores = all_results[k]\n",
    "    print(f\"k={k}: mean={np.mean(scores):.3f}, std={np.std(scores):.3f}, scores={[f'{s:.3f}' for s in scores]}\")\n",
    "\n",
    "# Find most frequently selected best k\n",
    "k_frequency = Counter(best_k_per_state)\n",
    "most_common_k = k_frequency.most_common(1)[0][0]\n",
    "print(f\"\\nMost frequently best k: {most_common_k} (selected {k_frequency[most_common_k]}/{len(random_states)} times)\")\n",
    "\n",
    "# Find k with highest mean accuracy\n",
    "best_mean_k = max(k_vals, key=lambda k: np.mean(all_results[k]))\n",
    "print(f\"k with highest mean accuracy: {best_mean_k} (mean={np.mean(all_results[best_mean_k]):.3f})\")\n",
    "\n",
    "# Use the k with highest mean accuracy\n",
    "final_k = best_mean_k\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"FINAL RECOMMENDATION: k={final_k}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Now get features for the final k using the original random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.35,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"oversample\", RandomOverSampler(random_state=42)),\n",
    "    (\"feature_selector\", SelectKBest(mutual_info_classif, k=final_k)),\n",
    "    (\"clf\", SVC(kernel='rbf', random_state=42))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "# Get selected features\n",
    "selected_features_mask = final_pipeline.named_steps['feature_selector'].get_support()\n",
    "selected_feature_names = X.columns[selected_features_mask].tolist()\n",
    "\n",
    "print(f\"\\nFinal model performance (random_state=42):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"\\nTop {final_k} features selected:\")\n",
    "for i, feature in enumerate(selected_feature_names, 1):\n",
    "    print(f\"  {i}. {feature}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f334dc-435a-480e-805d-df4c95eae440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8504e3d0-8507-4c50-bd6c-490f77321e48",
   "metadata": {},
   "source": [
    "CONCLUSION: \n",
    "- (StratefiedKFold + No data split) is BETTER than (No StratefiedKFold + Data split)\n",
    "    - This is bec in latter we see precision/recall = 0.0 \n",
    "- With k=10 features fro SelectKBest perform consistently well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36f778-8fff-4912-92ad-340c9fe997d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
