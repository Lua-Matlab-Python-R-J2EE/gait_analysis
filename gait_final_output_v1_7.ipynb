{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c1183c-d137-4c60-ae56-f1234f55342a",
   "metadata": {},
   "source": [
    "GAIT ANALYSIS (Oversampled data (INSIDE PIPELINE) + Stratified KFold + No Train/Test Split)\n",
    "\n",
    "Data Credits: https://archive.ics.uci.edu/dataset/604/gait+classification\n",
    "\n",
    "Dataset\n",
    "- Size: 48 samples (16 subjects, 3 samples/class)\n",
    "- No train/test split: All 48 samples used for cross-validation\n",
    "- CV Strategy: StratifiedKFold (n_splits=2)\n",
    "\n",
    "Key Strategy: Oversampling inside pipeline\n",
    "- StratifiedKFold: Splits data into 2 folds while preserving class distribution\n",
    "- Each fold:\n",
    "    - Oversampling applied only to training fold (via pipeline)\n",
    "    - Test fold remains original, unmodified data\n",
    "- No data leakage: Synthetic samples never appear in test sets\n",
    "- Pipeline Components:\n",
    "    - StandardScaler\n",
    "    - RandomOverSampler (Class balancing (inside pipeline, no leakage)) \n",
    "    - SelectKBest: Feature selection (tested with k = 2, 3, 4, 5, 10, 15)\n",
    "    - SVC: RBF kernel classifier\n",
    "  \n",
    "Why StratifiedKFold Works Better (vs. Person-Independent)\n",
    "- StratifiedKFold ensures balanced class distribution in each fold\n",
    "- Each fold contains at least 1 sample per subject\n",
    "- Model sees all subjects during training (1–2 samples per subject in each fold)\n",
    "- Oversampling provides sufficient training data per fold\n",
    "- Model learns subject-specific patterns since all subjects are represented\n",
    "- No data leakage: Oversampling occurs after split, inside pipeline\n",
    "\n",
    "Consequences:\n",
    "- Model learns from every subject in every fold\n",
    "- Evaluation reflects intra-subject discrimination (can it distinguish known subjects?)\n",
    "\n",
    "Upside:\n",
    "- All subjects appear in training\n",
    "- Oversampling works effectively\n",
    "- Model can learn subject-specific patterns\n",
    "\n",
    "Downside: Not person-independent\n",
    "- Person-independent: Train on subjects 1–12 -> Test on 13–16 (unseen people)\n",
    "- This setup: Train on all 16 subjects -> Test on different samples from the same 16 subjects\n",
    "- Problem: Subject leakage across folds\n",
    "- Model learns to recognize known individuals, not new ones\n",
    "- Overly optimistic accuracy due to familiarity with subjects\n",
    "\n",
    "Valid Interpretations\n",
    "- Features can distinguish between known subjects\n",
    "- Subject gait patterns are consistent across trials\n",
    "- Classification is possible given sufficient data\n",
    "- Feature selection identifies optimal discriminative features\n",
    "- Methodology is correct (no data leakage)\n",
    "\n",
    "Invalid Interpretations\n",
    "- Generalization to new people: Cannot identify unseen individuals\n",
    "- Biometric deployment: Not ready for real-world identification\n",
    "- Person-independent recognition: Does not test recognition of strangers\n",
    "- Cross-population performance: Only validates within 16 subjects\n",
    "\n",
    "Conclusion\n",
    "- Sound methodolofy for testing intra-subject discrimination (can features distinguish known subjects?)\n",
    "- Not sound for inter-subject generalization (can the model identify unseen individuals?).\n",
    "- It validates feature discriminability and pattern consistency, but not real-world generalization.\n",
    "\n",
    "Other notes\n",
    "- Test samples here are NEVER oversampled\n",
    "- Test samples are ORIGINAL data, not synthetic copies\n",
    "- Each test sample is completely independent from training synthetic data\n",
    "- Question: No Train/Test Split ≠ Data Leakage\n",
    "            If there's no train/test split, isn't everything mixed together?\n",
    "- Answer: No, because StratifiedKFold CREATES splits internally\n",
    "          Here we doesn't have a permanent train/test split\n",
    "          But StratifiedKFold creates temporary train/test splits for each fold\n",
    "          Oversampling happens WITHIN each fold (only on that fold's training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7555c83-4461-4d77-9b13-b782e203105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from imblearn.pipeline import Pipeline      \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c2a3a23-f598-4947-acea-017ff864dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0, k:2, accuracy:0.4375\n",
      "i:1, k:3, accuracy:0.6041666666666666\n",
      "i:2, k:4, accuracy:0.5416666666666666\n",
      "i:3, k:5, accuracy:0.6041666666666666\n",
      "i:4, k:10, accuracy:0.75\n",
      "i:5, k:15, accuracy:0.7083333333333334\n",
      "best_idx: 4\n",
      "==================================================\n",
      "Classification report for best accuracy at k=10, accuracy:0.75\n",
      "('              precision    recall  f1-score   support\\n'\n",
      " '\\n'\n",
      " '           0       0.60      1.00      0.75         3\\n'\n",
      " '           1       0.67      0.67      0.67         3\\n'\n",
      " '           2       0.40      0.67      0.50         3\\n'\n",
      " '           3       0.50      0.33      0.40         3\\n'\n",
      " '           4       1.00      1.00      1.00         3\\n'\n",
      " '           5       0.67      0.67      0.67         3\\n'\n",
      " '           6       0.75      1.00      0.86         3\\n'\n",
      " '           7       1.00      0.33      0.50         3\\n'\n",
      " '           8       0.50      0.33      0.40         3\\n'\n",
      " '           9       1.00      1.00      1.00         3\\n'\n",
      " '          10       1.00      0.67      0.80         3\\n'\n",
      " '          11       0.75      1.00      0.86         3\\n'\n",
      " '          12       1.00      0.33      0.50         3\\n'\n",
      " '          13       1.00      1.00      1.00         3\\n'\n",
      " '          14       1.00      1.00      1.00         3\\n'\n",
      " '          15       0.75      1.00      0.86         3\\n'\n",
      " '\\n'\n",
      " '    accuracy                           0.75        48\\n'\n",
      " '   macro avg       0.79      0.75      0.73        48\\n'\n",
      " 'weighted avg       0.79      0.75      0.73        48\\n')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load and identify X and y\n",
    "df_new = pd.read_csv(\"gait_final_output_updated.csv\")\n",
    "\n",
    "X = df_new.drop(columns=['Subject_ID_Y'])\n",
    "y = df_new['Subject_ID_Y']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy = {}\n",
    "\n",
    "k_vals = [2, 3, 4, 5, 10, 15]\n",
    "for k in k_vals:\n",
    "    accuracy[k] = {}\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"oversample\", RandomOverSampler()),\n",
    "        (\"feature_selector\", SelectKBest(mutual_info_classif, k=k)),\n",
    "        (\"clf\", SVC(kernel='rbf'))\n",
    "    ])\n",
    "    \n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=cv, n_jobs=-1)   \n",
    "    score = accuracy_score(y, y_pred)\n",
    "    # print(\"Accuracy:\", score)\n",
    "    accuracy[k]['score']  =  score\n",
    "    accuracy[k]['report'] =  classification_report(y, y_pred, zero_division=0)\n",
    "    \n",
    "# pprint.pprint(\"accuracy: \", accuracy)\n",
    "\n",
    "best_acc = []\n",
    "for i, k in enumerate(k_vals):\n",
    "    print(f\"i:{i}, k:{k}, accuracy:{accuracy[k]['score']}\" )\n",
    "    best_acc.append( accuracy[k]['score'] )\n",
    "\n",
    "best_idx = np.argmax(best_acc)\n",
    "print(\"best_idx:\", best_idx)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"Classification report for best accuracy at k={ k_vals[best_idx] }, accuracy:{accuracy[ k_vals[best_idx] ]['score']}\" )\n",
    "pprint.pprint( accuracy[ k_vals[best_idx] ]['report'] )\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec2c20-0c0a-49ef-a633-626d9e0c1c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b81b5eb6-a422-4ea3-9e0b-d8f282e3a47e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36f778-8fff-4912-92ad-340c9fe997d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
